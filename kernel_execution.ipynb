{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Execution API\n",
    "\n",
    "If you've written a computation kernel that you now want to execute through the DECADES framework, this is the right document for you!\n",
    "<br><br>\n",
    "If you haven't written your kernel, or have questions about how to write a kernel, please see the [_kernel implementation API_](kernel_implementation.ipynb) documentation.\n",
    "<br><br>\n",
    "If you are unsure what a _kernel_ is, please read the DECADES executive summary in the [_developers introduction guide_](developers_guide.ipynb)\n",
    "<br><br>\n",
    "\n",
    "<span style=\"background-color: #F8E0F7\"><font color=\"black\"> Remember!!! \n",
    "You can only have one kernel function per script! But feel free to write as many scripts as you'd like.</span>\n",
    "<br><br>\n",
    "\n",
    "## Kernel Signature\n",
    "The _signature_ of a kernel, i.e. its arguments, has a few restrictions. We don't think you'll find them too difficult, and may even be helpful down the road for you. \n",
    "<br><br>\n",
    "#### No return value\n",
    "\n",
    "A kernel should not return a value, or a tuple, or anything. \n",
    "<br><br>\n",
    "Calm down. We know what you're thinking. A kernel _needs_ to return something, otherwise why do any computation at all!\n",
    "<br><br>\n",
    "You can return as many values as you want through arguments!\n",
    "<br><br>\n",
    "Thus, a Numba function signature that looks like this: `int32(int32[:])`, i.e. a function that takes an integer array and returns an integer, would be changed to: `(int32[:],int32[:])` and you'd store the return value in 0th location of the second arg. See our example on [Reduction](Numba_Examples.ipynb) to see how this is done.\n",
    "<br><br>\n",
    "If you are not comfortable with Numba function signatures, please revisit their documenation [here](https://numba.pydata.org)\n",
    "<br><br>\n",
    "##### example\n",
    "Consider this example that returns the length of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(int32(int32[:]))\n",
    "def length_of_array(s):\n",
    "    return len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the function from returning a value, to returning through an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit((int32[:], int32[:]))\n",
    "def length_of_array(s, return_array):\n",
    "    return_array[0] = len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that you will have to declare your return argument before calling the function, e.g. `return_arg = np.zeros(1, dtype=np.int32)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile ID and number of tiles\n",
    "\n",
    "A kernel should take in all arguments required for computation and return. _But_ a DECADES kernel must take 2 additional special arguments. Both are of type int32 and represent a unique Tile ID and the number of tiles. \n",
    "<br><br>\n",
    "Recall that DECADES is a fundamentally parallel system. When you launch a DECADES kernel, you actually launch many instances of the same kernel in parallel. These kernels can access different data or branch to distinct computation using their unique tile ID and the total number of tiles. \n",
    "<br><br>\n",
    "You can set the number of tiles to launch your kernel with using the function `DEC_Options.set_num_threads`, described later on this page. You will never call the kernel directly. It will be called using decades kernel launcher described later in this document.\n",
    "<br><br>\n",
    "#### Shared Memory\n",
    "\n",
    "Our shared memory model is simple. \n",
    "\n",
    "* For arguments: Anything that is an array is shared. Anything that is a scaler is private.\n",
    "* local variables:\n",
    "  * scalars: not shared\n",
    "  * arrays: _sharing is current undefined_\n",
    "<br><br>\n",
    "#### Note\n",
    "\n",
    "This time of parallelism might remind you of popular GPU programming models: CUDA and OpenCL. Where a single kernel is executed by many threads and shared memory is passed in through arguments.\n",
    "<br><br>\n",
    "#### Important!\n",
    "\n",
    "Even if you write a single-threaded kernel, the kernel _must_ still take these two arguments. \n",
    "<br><br>\n",
    "##### Example\n",
    "\n",
    "Consider this example that computes `c = a + b` for two int32 arrays: `a` and `b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit((int32[:],int32[:],int32[:]))\n",
    "def array_add(a,b,c):\n",
    "    for i in range(len(a)):\n",
    "        c[i] = a[i] + b[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "to be a DECADES kernel, this must take two additional arguements, even if they are unused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit((int32[:],int32[:],int32[:], int32, int32))\n",
    "def array_add(a,b,c, tid, num_tiles):\n",
    "    for i in range(len(a)):\n",
    "        c[i] = a[i] + b[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "Now you have access to multiple tiles, you may as well use them! This program is _embarassingly_ parallel and can easily be made parallel using the tid and num_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit((int32[:],int32[:],int32[:], int32, int32))\n",
    "def array_add(a,b,c, tid, num_tiles):\n",
    "    for i in range(tid, len(a), num_tiles):\n",
    "        c[i] = a[i] + b[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## DECADES Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're getting closer to actually executing our kernel! We now need to tell Numba to compile the computation kernel through the DECADES compiler framework. This is conveniently provided as the `DEC_Pipeline` which can be imported and given in the 'njit' signature.\n",
    "<br><br>\n",
    "We also recommend using the `nogil=True` option in the `@njit` signature. _But_ please do not use `Parallel=True`. We handle our parallelism explicitly through the tile id and number of tiles described above.\n",
    "<br><br>\n",
    "Any function that you expect to call in the kernel must also be given with an `@njit` signature with the `DEC_Pipeline`\n",
    "<br><br>\n",
    "##### Example\n",
    "\n",
    "Consider our array_add kernel from above. We need to pass the DEC_Pipeline to ensure it is compiled through our framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DEC_Pipeline import DEC_Pipeline\n",
    "\n",
    "@njit((int32[:],int32[:],int32[:], int32, int32), nogil=True, pipeline_class=DEC_Pipeline)\n",
    "def array_add(a,b,c, tid, num_tiles):\n",
    "    for i in range(tid, len(a), num_tiles):\n",
    "        c[i] = a[i] + b[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know that the kernel will be compiled through the DECADES framework!\n",
    "<br><br>\n",
    "## Compiler Options\n",
    "\n",
    "Before compiling the kernel, we can set a variety options. These can accessed in through the DEC_Options class, part of the DEC_Pipeline. Its best to include this when including the DEC_Pipeline. Please note that these must be called before the kernel launcher (described below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DEC_Pipeline import DEC_Pipeline, DEC_Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Tiles\n",
    "\n",
    "This options sets the number of tiles to launch the kernel with. Probably best to start with `1` for development and then scale up as you become comfortable. The kernel launcher (described below) will then launch the kernel with the number tiles and provide each kernel with a unique tile id and the number of tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEC_Options.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next command can get the number of threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_num_threads = DEC_Options.get_num_threads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoupling Supply and Execute\n",
    "\n",
    "This options sets the compiler to generate a supply and execute kernel that communicate through a specialized API. This implements the latency-hiding techniques described in this [paper](http://mrmgroup.cs.princeton.edu/papers/taejun_micro15.pdf):\n",
    "<br><br>\n",
    "\n",
    "It is likely that this setting will not provide a speedup at all when executing, and likely will provide a slowdown. It is a hardware/software co-design feature and should be executed through the simulator, which simulates the necessary hardware additions to see improvements from this feature. Please see the next section (simulator backend) for more details.\n",
    "<br><br>\n",
    "Executing a kernel with this feature enabled will dump emulation stats about the number and type of communications between the compute and supply tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEC_Options.set_decoupled_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulator Backend\n",
    "\n",
    "This option compiles the kernel with the appropriate tracing instrumentation. This is likely not useful in early stages of development. Additionally, it causes _significant_ overhead, because of the trace generation. \n",
    "<br><br>\n",
    "If you are interested in running the simulator, please see the documentation [here](SDH_DECADES_Doc_and_Specs.pdf)\n",
    "<br><br>\n",
    "The other option to running the simulator (without this option) is to use an _evalution_ script, described in our [_evaulation_ documentation](evaluation_guide.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEC_Options.set_simulator_target()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preset Options\n",
    "\n",
    "It is also possible to run the kernel through a series of DECADES presets and automatically compare execution. This is documented in our [_evalutation_ documentation](evaluation_guide.ipynb). To enable the kernel to pickup these presents, you must\n",
    "\n",
    "1. Not include any of the above options\n",
    "\n",
    "2. Include this instruction: `DEC_Options.preset_config()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Launcher\n",
    "\n",
    "It is finally time to launch your kernel! We have provided a special mechanism to do this, in which the number of tiles, tile ids, simulator, etc. is taken care of behind the scenes for you (depending on which of the above options were set). \n",
    "<br><br>\n",
    "This is done through a special function that is part of the DEC_Pipeline called `decades_launch_kernel`. It is recommended to include this when including everything else from this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DEC_Pipeline import DEC_Pipeline, DEC_Options, decades_launch_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you've set up your kernel and options above, you can run your kernel using this function.\n",
    "\n",
    "It takes as arguments:\n",
    "\n",
    "1. The kernel function name\n",
    "2. All of the kernel arguments _except_ tile ID and number of tiles\n",
    "\n",
    "The function returns the time, in seconds it took to execute the kernel. Because compilation can take some time, this value reports the actual kernel compuation time.\n",
    "\n",
    "So if we use our array_add kernel above, we launch it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(1024, np.type=int32)\n",
    "# Populate a with data\n",
    "b = np.zeros(1024, np.type=int32)\n",
    "# Populate b with data\n",
    "c = np.zeros(1024, np.type=int32)\n",
    "# Populate c with data\n",
    "\n",
    "t = decades_launch_kernel(array_add, a,b,c)\n",
    "\n",
    "print(\"Time to run array_add kernel (seconds): \" + str(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "During this time, you will see the DEC++ (DECADES Compiler) command line call. This is useful to capture for bug reports or when asking for help. For example, depending on your compiler settings, you might see:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "executing DEC++:\n",
    "DEC++ -fn 1 --target numba -t 1 -m db DECADES_Numba_out > DECADES_Numba_out/dec_compile_log_std.txt 2> DECADES\\\n",
    "_Numba_out/dec_compile_log_stderr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will also be print outs letting you know when compilation is finished and when kernel execution has started.\n",
    "\n",
    "Although you should never have to directly deal with the DEC++ compiler directly when using the DECADES Numba flow, documentation can be found [here](SDH_DECADES_Doc_and_Specs.pdf). DEC++ is used directly for dealing with C++ and LLVM and is not a recommended way to program for DECADES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Once you've written a kernel, using numba, numpy and our associated kernel implementation documentation ([here](kernel_implementation.ipynb), then you can launch your kernel with various options using the API described here. Please remember:\n",
    "\n",
    "* Only one kernel launch per script. \n",
    "* Kernels cannot directly return values\n",
    "* Kernel _must_ contain a tile id and number of tiles argument (both int32), even if they are single threaded\n",
    "* Do not call a kernel directly. Use the `decades_kernel_launch` function. \n",
    "\n",
    "<br><br>\n",
    "##### Example.\n",
    "\n",
    "Here is an example of the array_length kernel from above, all put together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# include necessary packages\n",
    "from DEC_Pipeline import DEC_Pipeline, DEC_Options, decades_launch_kernel\n",
    "\n",
    "# Even though it is single threaded, still need extra two parameters (tid and num_tiles)\n",
    "# Make sure to compile with DEC_Pipeline\n",
    "@njit((int32[:], int32[:]), int32, int32, nogil=True, pipeline_class=DEC_Pipeline) \n",
    "def length_of_array(s, return_array, tid, num_tiles):\n",
    "    # it may be called with multiple tiles, but we only want one tile to do this work\n",
    "    if tid == 0:     \n",
    "        # return values through arg arrays\n",
    "        return_array[0] = len(s)\n",
    "        \n",
    "#set kernel to be launched with 2 threads\n",
    "DEC_Options.set_num_threads(2)\n",
    "\n",
    "my_array = np.zeros(1024, dtype = np.int32)\n",
    "return_array = np.zeros(1, dtype = np.int32)\n",
    "\n",
    "t = decades_launch_kernel(length_of_array, my_array, return_array)\n",
    "assert(return_array[0] == 1024)\n",
    "print(\"Kernel execution time (seconds): \" + str(t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
