{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Guide\n",
    "\n",
    "If you've written a kernel and want to get estimates on how well it performs on the DECADES architecture, this is the guide for you!\n",
    "\n",
    "We've wrapped up some nice presets, the compilation run, and the simulator run all in two nice packages (one for the Numba route and one for the TensorFlow route). We've even got baseline numbers from some baseline implementations that you can compare against.\n",
    "\n",
    "We'll be using the two examples from the Numba example [documentation](Numba_Decades_Examples.ipynb), i.e. matrix multiplication and reduction. You would see a very similar interface and output for a TensorFlow application.\n",
    "\n",
    "## Specification\n",
    "\n",
    "Our evaluation tools expect your Python tools to have a certain specification so we can keep things consistent between applications more easily. The specification is:\n",
    "\n",
    "`<app_name>.py`\n",
    "\n",
    "Essentially, your script should not take in any arguments.\n",
    "\n",
    "### Script and Input Naming\n",
    "\n",
    "With respect to what you name the script: please use the application name as the script name _if you want to compare against a baseline_.\n",
    "\n",
    "We use a simple text analysis to try and automatically determine which baseline you are aiming to implement, but this it is not perfect.\n",
    "\n",
    "For example, if you are programming the application \"Scan Statistics\", please make sure your script name contains \"Scan_Statistics\" in it somewhere.\n",
    "\n",
    "### Baselines\n",
    "\n",
    "We currently have some baseline numbers hardcoded in for applications of interest. Please contact us ASAP if you believe you should have a baseline to compare against, but the program is unable to find one.\n",
    "\n",
    "Finally, if you are running an application with the Numba framework, our evaluator will automatically set some default presets for you that we think will mirror our 2020 system. To use these presets, please remove all `DEC_Options` settings from your script (see [here](Decades_Numba_Pipeline.ipynb)) and add the single line: `DEC_Options.preset_config()`.\n",
    "\n",
    "### Computation Representations\n",
    "\n",
    "For many applications, it will be infeasible to run our cycle-accurate simulator to completion for the full application. When you want to run your application through the DECADES simulator for evaluation purposes, you should run a small representative computation. For example, the TensorFlow framework should simulate only one item (e.g. image) of computation (forward and backward propagation). The evaluation metric of interest, GOPs/Watt, is time agnostic. This means that assuming you have selected an appropriate computation sample, the measured average power of this computation remains the same over multiple samples and epochs. For Numba applications where multiple kernel iterations are involved, we recommend simulating one iteration of the kernel.\n",
    "\n",
    "## Running the Evaluator \n",
    "\n",
    "If your script fits the above specification, then you can run it through the evaluator! We have two very similar programs 1) `decades_numba_presets` for applications suitable for the DECADES Numba framework and 2) `decades_tf_presets` for DECADES TensorFlow applications. Instead of running `python`, you can now run these program instead!\n",
    "\n",
    "For example, we previously tested `mat_mul.py` by running:\n",
    "\n",
    "`$ python mat_mul.py`\n",
    "\n",
    "To run this example through the evalutor, we can now run:\n",
    "\n",
    "`$ decades_numba_presets mat_mul.py`\n",
    "\n",
    "Note: this application is small enough that we can it run in its entirety without needing to focus on a smaller computation representation.\n",
    "\n",
    "This script does both a compiler and simulator pass and may take quite some time to run, so _please be patient_. For extremely large datasets, this could take up to several hours. We hope you will try evaluating on smaller data sets first to grow comfortable with the system.\n",
    "\n",
    "Luckily, our two examples are small enough to run in this framework in about a minute.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "If we try running our matrix multiplication using the command:\n",
    "\n",
    "`$ decades_numba_presets mat_mul.py`\n",
    "\n",
    "We should see some outputs about running the application, compiler, simulator, etc. The important output at the end should look something like this:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "raw results\n",
    "-----\n",
    "chip                 GOPS/Watt\n",
    "-----------------  -----------\n",
    "baseline               1.26087\n",
    "decades framework      6.79576\n",
    "\n",
    "DECADES framework improves over baseline by:\n",
    "chip                 GOPS/Watt\n",
    "-----------------  -----------\n",
    "decades framework       5.390x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this means our DECADES architecture achieved approximately a 5x increase in energy efficiency over a baseline matrix multiplication run on the baseline system! Pretty cool!\n",
    "\n",
    "You can play with the implementation of matrix multiplication to see if you can improve or worsen this value based on design decisions.\n",
    "\n",
    "#### Note\n",
    "\n",
    "the metric obtained here is just GOPs/Watt, or giga operations per watt. It's not necessarily fast processing that raises this number. For example, a multithreaded application that does not scale well might actually lower this number (due to more cores using more energy), even if it computes slightly faster.\n",
    "\n",
    "Our DECADES chip uses a low-power, in-order processor design to help increase this metric. We encourage you to play with multithreaded examples and different implementation choices. \n",
    "\n",
    "#### Inputs\n",
    "\n",
    "If you want to run your script on a different input, please go ahead and try! The only issue is that the baseline is stored only for one input per application. Thus the comparison will not be accurate at all, but read on to the next section to learn how to get raw outputs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbose Output\n",
    "\n",
    "We think you might be interested in other metrics, even if you can't compare to the baseline, so we've added a way for you to do this. Simply use the same evaluator script, but set the environment variable `DECADES_VERBOSE` to the value `1`\n",
    "\n",
    "This produces a more interesting table, which includes other metrics such as the number of cycles and power measurements:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "raw results\n",
    "-----\n",
    "chip                 cycles    global_energy    global_avg_power    GOPS/Watt\n",
    "-----------------  --------  ---------------  ------------------  -----------\n",
    "baseline                 NA               NA                  NA           NA\n",
    "decades framework    370742      1.93081e-06           0.0260398           NA\n",
    "\n",
    "DECADES improves over baseline by:\n",
    "-----\n",
    "chip                 cycles    global_energy    global_avg_power    GOPS/Watt\n",
    "-----------------  --------  ---------------  ------------------  -----------\n",
    "decades framework        NA               NA                  NA           NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still a lot of `NA` values in there because a baseline value is not available, but this feature allows you to peek under the hood and see more metrics and gain more insight on how your application is running through the DECADES framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Multiple Tiles (Threads) for Numba Applications\n",
    "\n",
    "The safest option for the evaluator is to run your kernel single threaded. That's okay, there are still a lot of transparent optimizations that happen (e.g. different hardware technology and supply/compute decoupling). \n",
    "\n",
    "If you are adventurous (and we hope you will be!), you can explicitly tell your script to run with multiple tiles. If your application scales well, then you will likely see these metrics change in your favor!\n",
    "\n",
    "To do this, after the `DEC_Options.preset_config()`, simply add a call to `DEC_Options.set_num_tiles(N)`, where N is the number of tiles you want to run with.\n",
    "\n",
    "If you don't remember the parallel framework, please jog your memory by looking at the kernel execution documentation (here)[Decades_Numba_Pipeline.ipynb]\n",
    "\n",
    "## Simulating Without the Evaluator\n",
    "\n",
    "You can run the simulator (Pythia) without the evaluator scripts. The command is `pythiarun` and it will be in the Docker path. Running with the `-h` flag will show you a list of options. You can additionally examine the readme in: `/decades/simulator/README.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "\n",
    "Using our transparent optimizations (e.g. hardware technology and decoupling), multiple tiles, and clever algorithmic choices, we have been able to see impressive gains over the many baseline implementations (over 1000x in some cases)!\n",
    "\n",
    "We hope you have a similar experience and please contact us for any question or comments!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
